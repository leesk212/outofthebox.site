---
tags: machine-learning svm
toc: True
---
<!-- #region _cell_guid="ce53be83-4475-8d60-f4a5-b7baa884bd11" -->
Here I m going to run **Support Vector machine** with different **kernels(linear,gaussian,polynomial)** and also tune the various parameters such as **C** ,**gamma** and **degree** to find out the best performing model .
<!-- #endregion -->

```python 
# This Python 3 environment comes with many helpful analytics libraries installed  
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python  
# For example, here's several helpful packages to load in   


# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

from subprocess import check_output
print(check_output(["ls", "../input"]).decode("utf8"))

# Any results you write to the current directory are saved as output.
```

<!-- #region _cell_guid="cd01fe18-db57-3da4-2916-f99e096988ac" -->
# Importing all the necessary libraries
<!-- #endregion -->

```python 
import pandas as pd
import numpy as np
import seaborn as sns

import matplotlib.pyplot as plt

%matplotlib inline
```

<!-- #region _cell_guid="0200d0e4-320f-2822-88a9-f6c0225658e6" -->
# Reading the comma separated values file into the dataframe
<!-- #endregion -->

```python  
df = pd.read_csv('../input/voice.csv')
df.head()
```

<!-- #region _cell_guid="2d654f09-1018-5498-e4ea-428752a19d4b" -->
# Checking the correlation between each feature
<!-- #endregion -->

```python 
df.corr()
```

<!-- #region _cell_guid="51c112a4-8b80-2a6a-5688-825581b9c1dd" -->
# Checking whether there is any null values 
<!-- #endregion -->

```python _cell_guid="af637554-1c8d-cdf4-c76e-6429511dbcf7"
df.isnull().sum()
```

```python 
df.shape
```

```python 
print("Total number of labels: {}".format(df.shape[0]))
print("Number of male: {}".format(df[df.label == 'male'].shape[0]))
print("Number of female: {}".format(df[df.label == 'female'].shape[0]))
```

<!-- #region _cell_guid="af99e2cb-9132-7c97-3dce-6a81c6b85bb9" -->
Thus we can see there are equal number of male and female labels
<!-- #endregion -->

```
df.shape
```

<!-- #region _cell_guid="85fbbf85-f199-9528-8147-7583154c4c6e" -->
There are 21 features and 3168 instances.
<!-- #endregion -->

<!-- #region _cell_guid="35926698-93b2-6af7-7647-20e876461359" -->
# Separating features and labels
<!-- #endregion -->

```python 
X=df.iloc[:, :-1]
X.head()
```

<!-- #region _cell_guid="eabb15db-3594-8ad5-2a5b-10527ac27b88" -->
# Converting string value to int type for labels
<!-- #endregion -->

```python 
from sklearn.preprocessing import LabelEncoder
y=df.iloc[:,-1]

# Encode label category
# male -> 1
# female -> 0

gender_encoder = LabelEncoder()
y = gender_encoder.fit_transform(y)
y
```

<!-- #region _cell_guid="c4badc10-5597-845a-85e2-c8cbf4c3e0d4" -->
# Data Standardisation
Standardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance). It is useful to standardize attributes for a model. Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data.
<!-- #endregion -->

```python 
# Scale the data to be between -1 and 1
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X)
X = scaler.transform(X)
```

<!-- #region _cell_guid="31ce4128-0a4a-ae10-3a25-1c362398295c" -->
# Splitting dataset into training set and testing set for better generalisation
<!-- #endregion -->

```python 
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
```

<!-- #region _cell_guid="416eb826-73fc-bbd2-0676-2a803ae9327b" -->
# Running SVM with default hyperparameter.
<!-- #endregion -->

```python 
from sklearn.svm import SVC
from sklearn import metrics
svc=SVC() #Default hyperparameters
svc.fit(X_train,y_train)
y_pred=svc.predict(X_test)
print('Accuracy Score:')
print(metrics.accuracy_score(y_test,y_pred))
```

<!-- #region _cell_guid="e5548edc-79be-2f23-a994-ddb73e82ee22" -->
# Default Linear kernel
<!-- #endregion -->

```python 
svc=SVC(kernel='linear')
svc.fit(X_train,y_train)
y_pred=svc.predict(X_test)
print('Accuracy Score:')
print(metrics.accuracy_score(y_test,y_pred))
```

<!-- #region _cell_guid="12039039-6d6e-915c-d213-50c102eb3c09" -->
# Default RBF kernel
<!-- #endregion -->

```python 
svc=SVC(kernel='rbf')
svc.fit(X_train,y_train)
y_pred=svc.predict(X_test)
print('Accuracy Score:')
print(metrics.accuracy_score(y_test,y_pred))
```

<!-- #region _cell_guid="200005e4-4577-0fc3-e833-a438cbf5ceff" -->
We can conclude from above that svm by default uses **rbf** kernel as a parameter for kernel
<!-- #endregion -->

<!-- #region _cell_guid="3392a4d6-6ed0-49d0-7868-038f2489e8c8" -->
# Default Polynomial kernel
<!-- #endregion -->

```python 
svc=SVC(kernel='poly')
svc.fit(X_train,y_train)
y_pred=svc.predict(X_test)
print('Accuracy Score:')
print(metrics.accuracy_score(y_test,y_pred))
```

<!-- #region _cell_guid="fc3a244d-4ef3-34f4-eb3a-3286772145b2" -->
Polynomial kernel is performing poorly.The reason behind this maybe it is overfitting the training dataset
<!-- #endregion -->

<!-- #region _cell_guid="a54fb78f-de14-da2f-fe18-605b3f5180d5" -->
# Performing K-fold cross validation with different kernels
<!-- #endregion -->

<!-- #region _cell_guid="ad1fe233-c013-d253-9596-f23e1a11c347" -->
# CV on Linear kernel
<!-- #endregion -->

```python 
from sklearn.cross_validation import cross_val_score
svc=SVC(kernel='linear')
scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy') #cv is cross validation
print(scores)
```

<!-- #region _cell_guid="f1e11e9e-0d61-70cb-8d80-3c31fcce6cef" -->
We can see above how the accuracy score is different everytime.This shows that accuracy score depends upon how the datasets got split.
<!-- #endregion -->

```python 
print(scores.mean())
```

<!-- #region _cell_guid="6d61c1df-0285-0a0e-64ad-c2bef642e15d" -->
In K-fold cross validation we generally take the mean of all the scores.
<!-- #endregion -->

<!-- #region _cell_guid="5236f0a2-7d83-d6cb-fb88-2aacf70fea4c" -->
# CV on rbf kernel
<!-- #endregion -->

```python 
from sklearn.cross_validation import cross_val_score
svc=SVC(kernel='rbf')
scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy') #cv is cross validation
print(scores)
```

```python 
print(scores.mean())
```

<!-- #region _cell_guid="9e261f77-d75e-f6f5-833b-a30a9feee04d" -->
# CV on Polynomial kernel
<!-- #endregion -->

```python 
from sklearn.cross_validation import cross_val_score
svc=SVC(kernel='poly')
scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy') #cv is cross validation
print(scores)
```

```python 
print(scores.mean())
```

<!-- #region _cell_guid="7a264296-51e3-904b-ab6b-4f86d0358f53" -->
**When K-fold cross validation is done we can see different score in each iteration.This happens because when we use train_test_split method,the dataset get split in random manner into testing and training dataset.Thus it depends on how the dataset got split and which samples are training set and which samples are in testing set.**

**With K-fold cross validation we can see that the dataset got split into 10 equal parts thus covering all the data into training as well into testing set.This is the reason we got 10 different accuracy score.**
<!-- #endregion -->

<!-- #region _cell_guid="0912611e-a132-cd7e-edcf-8f63603a7f38" -->
### Taking all the values of C and checking out the accuracy score with kernel as linear.
<!-- #endregion -->

<!-- #region _cell_guid="cad5cfc0-be06-ff7f-bb83-0d8e168d0cbf" -->
**The C parameter tells the SVM optimization how much you want to avoid misclassifying each training example. For large values of C, the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly. Conversely, a very small value of C will cause the optimizer to look for a larger-margin separating hyperplane, even if that hyperplane misclassifies more points.**

**Thus for a very large values we can cause overfitting of the model and for a very small value of C we can cause underfitting.Thus the value of C must be chosen in such a manner that it generalised the unseen data well**
<!-- #endregion -->

```python 
C_range=list(range(1,26))
acc_score=[]
for c in C_range:
    svc = SVC(kernel='linear', C=c)
    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')
    acc_score.append(scores.mean())
print(acc_score)    
    
```

```python 
import matplotlib.pyplot as plt
%matplotlib inline


C_values=list(range(1,26))
# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)
plt.plot(C_values,acc_score)
plt.xticks(np.arange(0,27,2))
plt.xlabel('Value of C for SVC')
plt.ylabel('Cross-Validated Accuracy')
```

<!-- #region _cell_guid="d9c892c1-0923-a8e3-53bf-40886621828c" -->
**From the above plot we can see that accuracy has been close to 97% for C=1 and C=6 and then it drops around 96.8% and remains constant.**
<!-- #endregion -->

<!-- #region _cell_guid="37666b87-8625-668f-6984-61be1852635b" -->
### Let us look into more detail of what is the exact value of C which is giving us a good accuracy score
<!-- #endregion -->

```python 
C_range=list(np.arange(0.1,6,0.1))
acc_score=[]
for c in C_range:
    svc = SVC(kernel='linear', C=c)
    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')
    acc_score.append(scores.mean())
print(acc_score)    
    
```

```python 
import matplotlib.pyplot as plt
%matplotlib inline

C_values=list(np.arange(0.1,6,0.1))
# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)
plt.plot(C_values,acc_score)
plt.xticks(np.arange(0.0,6,0.3))
plt.xlabel('Value of C for SVC ')
plt.ylabel('Cross-Validated Accuracy')
```

<!-- #region _cell_guid="d604755b-9603-9f61-d8d7-c533ba9851a9" -->
### Accuracy score is highest for C=0.1.
<!-- #endregion -->

<!-- #region _cell_guid="a8d63c32-a177-b287-08c4-f85f144c6324" -->
### Taking kernel as **rbf** and taking different values gamma
<!-- #endregion -->

<!-- #region _cell_guid="dea9c10d-0351-e3fd-0e11-50a7dd18c310" -->
**Technically, the gamma parameter is the inverse of the standard deviation of the RBF kernel (Gaussian function), which is used as similarity measure between two points. Intuitively, a small gamma value define a Gaussian function with a large variance. In this case, two points can be considered similar even if are far from each other. In the other hand, a large gamma value means define a Gaussian function with a small variance and in this case, two points are considered similar just if they are close to each other**
<!-- #endregion -->

```python 
gamma_range=[0.0001,0.001,0.01,0.1,1,10,100]
acc_score=[]
for g in gamma_range:
    svc = SVC(kernel='rbf', gamma=g)
    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')
    acc_score.append(scores.mean())
print(acc_score)    
    
```

```python 
import matplotlib.pyplot as plt
%matplotlib inline

gamma_range=[0.0001,0.001,0.01,0.1,1,10,100]

# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)
plt.plot(gamma_range,acc_score)
plt.xlabel('Value of gamma for SVC ')
plt.xticks(np.arange(0.0001,100,5))
plt.ylabel('Cross-Validated Accuracy')
```

<!-- #region _cell_guid="15e21695-add0-983e-6a87-c25b98fff692" -->
**We can see that for gamma=10 and 100 the kernel is performing poorly.We can also see a slight dip in accuracy score when gamma is 1.Let us look into more details for the range 0.0001 to 0.1.**
<!-- #endregion -->

```python 
gamma_range=[0.0001,0.001,0.01,0.1]
acc_score=[]
for g in gamma_range:
    svc = SVC(kernel='rbf', gamma=g)
    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')
    acc_score.append(scores.mean())
print(acc_score)    
    
```

```python 
import matplotlib.pyplot as plt
%matplotlib inline

gamma_range=[0.0001,0.001,0.01,0.1]

# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)
plt.plot(gamma_range,acc_score)
plt.xlabel('Value of gamma for SVC ')
plt.ylabel('Cross-Validated Accuracy')
```

<!-- #region _cell_guid="0708b835-3e46-82dc-c74b-0f6d34d9b51f" -->
The score increases steadily and raches its peak at 0.01 and then decreases till gamma=1.Thus Gamma should be around 0.01.
<!-- #endregion -->

<!-- #region _cell_guid="90f76105-a03f-0326-9676-46053a98db93" -->
Let us look into more detail for gamma values
<!-- #endregion -->

```python 
gamma_range=[0.01,0.02,0.03,0.04,0.05]
acc_score=[]
for g in gamma_range:
    svc = SVC(kernel='rbf', gamma=g)
    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')
    acc_score.append(scores.mean())
print(acc_score)    
    
```

```python 
import matplotlib.pyplot as plt
%matplotlib inline

gamma_range=[0.01,0.02,0.03,0.04,0.05]

# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)
plt.plot(gamma_range,acc_score)
plt.xlabel('Value of gamma for SVC ')
plt.ylabel('Cross-Validated Accuracy')
```

<!-- #region _cell_guid="651abf9c-4698-9c01-aa2d-cfe3144be51f" -->
**We can see there is constant decrease in the accuracy score as gamma value increase.Thus gamma=0.01 is the best parameter.**
<!-- #endregion -->

<!-- #region _cell_guid="413851c2-7bfd-859e-53a1-75ba442a678c" -->
## Taking polynomial kernel with different degree
<!-- #endregion -->

```python 
degree=[2,3,4,5,6]
acc_score=[]
for d in degree:
    svc = SVC(kernel='poly', degree=d)
    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')
    acc_score.append(scores.mean())
print(acc_score)    
    
```

```python 
import matplotlib.pyplot as plt
%matplotlib inline

degree=[2,3,4,5,6]

# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)
plt.plot(degree,acc_score,color='r')
plt.xlabel('degrees for SVC ')
plt.ylabel('Cross-Validated Accuracy')
```

<!-- #region _cell_guid="0b5454f1-2788-8627-f70e-1556983a82d9" -->
**Score is high for third degree polynomial and then there is drop in the accuracy score as degree of polynomial increases.Thus increase in polynomial degree results in high complexity of the model and thus causes overfitting.**
<!-- #endregion -->

<!-- #region _cell_guid="2143d3d8-4abf-983d-ee4c-cc74f4fde0b7" -->
## Now performing SVM by taking hyperparameter C=0.1 and kernel as linear 


----------
<!-- #endregion -->

```python 
from sklearn.svm import SVC
svc= SVC(kernel='linear',C=0.1)
svc.fit(X_train,y_train)
y_predict=svc.predict(X_test)
accuracy_score= metrics.accuracy_score(y_test,y_predict)
print(accuracy_score)
```

<!-- #region _cell_guid="b4cf3a4a-9f64-5567-3037-bc2719ae098c" -->
## With K-fold cross validation(where K=10)
<!-- #endregion -->

```python 
from sklearn.cross_validation import cross_val_score
svc=SVC(kernel='linear',C=0.1)
scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')
print(scores)
```

<!-- #region _cell_guid="daad2a8a-c37f-86b7-9120-8fb3a67cdc38" -->
Taking the mean of all the scores
<!-- #endregion -->

```python 
print(scores.mean())
```

<!-- #region _cell_guid="76ec14cd-f216-6179-063e-8ec211daa46c" -->
The accuracy is slightly good without K-fold cross validation but it may fail to generalise the unseen data.Hence it is advisable to perform K-fold cross validation where all the data is covered so it may predict unseen data well.
<!-- #endregion -->

<!-- #region _cell_guid="d8887f84-1f58-63f5-a35e-6423e816105a" -->
## Now performing SVM by taking hyperparameter gamma=0.01 and kernel as rbf
<!-- #endregion -->

```python 
from sklearn.svm import SVC
svc= SVC(kernel='rbf',gamma=0.01)
svc.fit(X_train,y_train)
y_predict=svc.predict(X_test)
metrics.accuracy_score(y_test,y_predict)
```

<!-- #region _cell_guid="e0b485e2-4ea3-ed6d-ece1-d29cda102038" -->
## With K-fold cross validation(where K=10)
<!-- #endregion -->

```python 
svc=SVC(kernel='linear',gamma=0.01)
scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')
print(scores)
print(scores.mean())
```

<!-- #region _cell_guid="b35afce0-4274-e96f-66f8-89a57fbc0d30" -->
## Now performing SVM by taking hyperparameter degree=3 and kernel as poly
<!-- #endregion -->

```python 
from sklearn.svm import SVC
svc= SVC(kernel='poly',degree=3)
svc.fit(X_train,y_train)
y_predict=svc.predict(X_test)
accuracy_score= metrics.accuracy_score(y_test,y_predict)
print(accuracy_score)
```

<!-- #region _cell_guid="1ef380ed-2e09-a0f8-3831-140df751f299" -->
## With K-fold cross validation(where K=10)
<!-- #endregion -->

```python 
svc=SVC(kernel='poly',degree=3)
scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')
print(scores)
print(scores.mean())
```

<!-- #region _cell_guid="3a81d277-41ee-f387-0745-1aba41754f40" -->
#Let us perform Grid search technique to find the best parameter
<!-- #endregion -->

```python 
from sklearn.svm import SVC
svm_model= SVC()
```

```python 
tuned_parameters = {
 'C': (np.arange(0.1,1,0.1)) , 'kernel': ['linear'],
 'C': (np.arange(0.1,1,0.1)) , 'gamma': [0.01,0.02,0.03,0.04,0.05], 'kernel': ['rbf'],
 'degree': [2,3,4] ,'gamma':[0.01,0.02,0.03,0.04,0.05], 'C':(np.arange(0.1,1,0.1)) , 'kernel':['poly']
                   }
```

```python 
from sklearn.grid_search import GridSearchCV

model_svm = GridSearchCV(svm_model, tuned_parameters,cv=10,scoring='accuracy')
```

```python 
model_svm.fit(X_train, y_train)
print(model_svm.best_score_)
```

```python 
#print(model_svm.grid_scores_)
```

```python 
print(model_svm.best_params_)
```

```python 
y_pred= model_svm.predict(X_test)
print(metrics.accuracy_score(y_pred,y_test))
```

<!-- #region _cell_guid="b7011956-298d-22ed-976c-2ffbf6954dd8" -->
You can find my notebook on Github:
("https://github.com/nirajvermafcb/Data-Science-with-python")
<!-- #endregion -->
